\chapter{Uvod}

\section{Motivacija}

Izračunljivost: matematička obrada pojma algoritma. Čemu to služi? Zar ne znamo pisati algoritme i bez matematičke formalizacije? Koga je zapravo briga za definicije poput "Algoritam je uređena sedmorka, čiji elementi su skupovi\ldots", i beskorisne propozicije poput "Postoji algoritam za sortiranje liste brojeva"? Dva su moguća odgovora na to pitanje: praktični i teorijski.

Kažemo da znamo pisati algoritme. Ali kako to činimo? Zapravo ih (najčešće) \emph{implementiramo} u nekom programskom jeziku, podrazumijevajući (prešutno ili eksplicitno) da je ono što taj jezik omogućava izraziti, ni više ni manje nego algoritam. S tim shvaćanjem postoje dva velika problema: prvi, programski jezici nastaju godišnjim ritmom, a jezik koji postane toliko popularan da se u njemu počnu pisati općeniti algoritmi, nastane možda svakih desetak godina. Zatrpani smo knjigama koje objašnjavaju besmrtne algoritamske koncepte, pokušavajući nam ih "približiti" implementirajući ih u jeziku koji je odavno mrtav. Neke od tih knjiga su toliko popularne da su autori gotovo primorani pisati nova izdanja, u kojima su algoritmi potpuno isti, ali je programski jezik promijenjen. Tu se krije implicitna pretpostavka da, što god jedan programski jezik može izraziti, može i drugi. No kako možemo biti sigurni u to? Na primjer, originalni FORTRAN nije dopuštao rekurziju, dok ALGOL jest~\cite{url:recursionAlgol}. Znamo li da se svaki rekurzivni algoritam može zapisati nerekurzivno? Možemo li to dokazati? Također, ako jest tako, zašto cijelo vrijeme stvaramo nove jezike? Razuman odgovor je da se razlikuju u \emph{nečem drugom}, ne u algoritmima koje prezentiraju. Možemo li to "drugo" eliminirati, svodeći algoritme samo na "čistu esenciju"?

Drugi problem sastoji se u tome da programski jezici nastaju s raznim svrhama, ali izuzetno rijetko s primarnom svrhom modeliranja matematičkih objekata. (Još rjeđe takvi jezici postanu planetarno popularni.) Obično su opterećeni performansama: optimalnom upotrebom procesora (vremena) i memorije (prostora), i kao posljedica toga njihov dizajn čini razne ustupke hardveru, koji se teško mogu matematički opravdati. Izuzetno je česta pojava, na primjer, da cijele brojeve računala ne reprezentiraju kao elemente skupa $\mathbb Z$, već kao elemente skupa $\mathbb Z\slash2^{64}\mathbb Z$. Također, često se sekvencijalnost (izvršavanje instrukcija redom kojim su pisane) žrtvuje u svrhu bržeg izvršavanja na višejezgrenim procesorima. Tada nastaje raskorak između algoritma i implementacije, koji ima važne praktične posljedice~\cite{url:wrongBinsearch}.

Teorijski odgovor na motivacijsko pitanje dobijemo kad se zapitamo što, u općenitom smislu, matematičare navede na formalizaciju nekog pojma. Ponekad je to otkriće paradoksa, ali češće se radi o potrebi da se dokaže \emph{nepostojanje} objekta neke klase $K$ s nekim svojstvima. Iako smo se za dokaze postojanja mogli osloniti na intuitivni osjećaj da objekte klase $K$ "prepoznamo kad ih vidimo", to nam očito više nije dovoljno ako slutimo da željeni objekt ne postoji, i želimo to dokazati. A u svakom se području s vremenom pojave problemi koji odolijevaju svim poznatim metodama napada, i počne se vjerovati da su možda nerješivi.

Dok nitko nije dovodio u pitanje Euklidove konstrukcije, puno je preciznija formulacija geometrijske konstruktibilnosti bila potrebna da se dokaže da je trisekcija kuta ravnalom i šestarom nemoguća. Dok je za pronalazak Cardanove ili Ferrarijeve formule bilo dovoljno znati nekoliko jednostavnih algebarskih manipulacija (i posjedovati dovoljno mašte), tek je Galoisova teorija omogućila dokaz da analogni postupci nisu mogući za algebarske jednadžbe petog i višeg stupnja. Dok je već Galileo vidio da prirodnih brojeva i njihovih kvadrata ima jednako mnogo koristeći intuitivni pojam bijekcije, bitno je stroža formulacija bila potrebna Cantoru za dijagonalni argument kojim je dokazao da bijekcija između $\N$ i $\mathbb R$ ne postoji. Na meta-razini također: Cantor je uspio naći dokaze za mnoge tvrdnje ili njihove negacije u svojoj teoriji skupova, ali tek je formalna aksiomatizacija omogućila da se dokaže da takvi dokazi za neke tvrdnje (kao što je hipoteza kontinuuma), niti za njihove negacije, jednostavno ne postoje.

Od davnina bio je poznat problem rješavanja \emph{diofantskih jednadžbi}, koji se sastoji u traženju prirodnih brojeva koji zajedno s još nekim fiksnim prirodnim brojevima, zbrajanjem i množenjem, čine dva izraza jednakima (primjer: $x\cdot x+1=y\cdot y\cdot y$). Modernim jezikom, zadan je polinom s cjelobrojnim koeficijentima u $k$ varijabli (u gornjem slučaju $x_2^3-x_1^2-1$), i želimo ustanoviti ima li nultočku u $\N^k$. Za mnoge specijalne polinome znali smo odgovor, za mnoge specijalne potklase (recimo kad je broj varijabli $k$, ili stupanj polinoma, jednak $1$) poznavali smo od davnina algoritme za nalaženje nultočaka, ali opći algoritam, koji bi za svaki takav polinom u konačno mnogo koraka odgovarao na pitanje ima li prirodnu nultočku, nismo imali. Na slavnoj Hilbertovoj listi od 23 velika matematička problema, deseti je pronalazak takvog algoritma. Protokom vremena, iskristalizirala se mogućnost da algoritam ne postoji, ali za pravi dokaz toga trebalo je prvo formalizirati pojam algoritma. Nakon što je to učinjeno, relativno brzo (uzevši u obzir da su diofantske jednadžbe bile poznate tisućama godina) je riješen i deseti Hilbertov problem --- naravno, dokazom nepostojanja takvog algoritma.

Nije to bio jedini takav problem: nađeni su brojni drugi problemi za koje se sličnim metodama dokazalo da su algoritamski nerješivi. Danas znamo da je neizračunljivost "posvuda", i nismo njome više toliko fascinirani, ali to je samo znak ogromnog puta koji smo prešli u shvaćanju algoritama tijekom dvadesetog stoljeća. Jedan mali dio tog puta prikazan je u ovoj knjizi.

\section{Osnovni pojmovi}
Da bismo odgovorili na pitanje što je algoritam, zapitajmo se za početak što algoritam \emph{radi} (ili, što mi algoritmom radimo). Očito, algoritam možemo \emph{pokrenuti} na nekim \emph{ulaznim podacima}, izvršavati njegove korake preciznim redom, te u nekom trenutku (kad algoritam to zatraži) zaustaviti postupak, i dobiti \emph{izlazne podatke}. Algoritam, u tom pogledu, obavlja nekakvu \emph{transformaciju} podataka. Štoviše, algoritam bi trebao biti \emph{deterministički}: isti ulazni podaci trebali bi proizvesti iste izlazne podatke. Matematička formalizacija te transformacije je pojam \emph{funkcije}: algoritam \emph{preslikava} ulazne podatke u izlazne. Kažemo da algoritam \emph{računa} funkciju, i takve funkcije (za koje imamo algoritme) zovemo \emph{izračunljivima}. Na taj način, pitanje "Koji su algoritmi mogući?" postaje nešto preciznije pitanje "Koje su funkcije izračunljive?".

No da bismo funkciju mogli matematički zapisati, moramo imati preciziranu domenu i kodomenu. Što su naši podaci?

\subsection{Vrste podataka}
Na prvi pogled, mogu biti bilo što: imamo algoritme koji rade na cijelim brojevima, realnim brojevima (preciznije, njihovim aproksimacijama --- vidjet ćemo zašto je to bitno), tekstnim podacima (\emph{strings}), datotekama, mrežnim vezama (\emph{sockets}), drugim algoritmima (\emph{higher order programming}), grafovima, objektima, regularnim izrazima, i tko zna čemu. No iskustvo programiranja nas uči da se svi ti raznorazni \emph{tipovi} podataka uvijek mogu (i moraju, ako želimo nešto konkretno raditi s njima) reprezentirati u memoriji računala kao neki binarni podaci: konačni nizovi nula i jedinica.

Dakle, mogli bismo uzeti $\{0,1\}^*:=\bigcup_{k\in\mathbb N}\{0,1\}^k$ kao univerzalni skup naših podataka --- ali pokazuje se da je puno zgodnije ako umjesto $\{0,1\}$ uzmemo proizvoljni konačni neprazni skup ("abecedu") $\Sigma$. Funkcije iz $\Sigma^*$ u $\Sigma^*$ zovemo \emph{jezične funkcije}, i to je povijesno bio prvi pokušaj formalizacije algoritma: Turingov stroj, kojim ćemo se baviti u kasnijem poglavlju%~\ref{chap:Turing}
.

Ipak, skup $\{0,1\}^*$ (a pogotovo općeniti $\Sigma^*$) je matematički nespretan; recimo, ako hoćemo nešto o njemu dokazati indukcijom, moramo u koraku posebno razmatrati dodavanje nule, a posebno dodavanje jedinice. Ili, ako hoćemo iterirati (napraviti neku petlju) kroz njega, nije baš lako odrediti sljedbenika zadanog elementa. Nezgoda je i u tome što uobičajenim (leksikografskim) uređajem nije dobro uređen: na primjer, skup $\{0^n1\mid n\in\N\}$ nema najmanji element.

Za dokazivanje teorema, puno je bolje uzeti jednostavniji skup, te ćemo u najvećem dijelu knjige promatrati \emph{brojevne} funkcije, za koje su ulazni i izlazni podaci \textbf{prirodni brojevi}. U nekom smislu, skup prirodnih brojeva je najjednostavniji mogući skup na kojem se može raditi teorija izračunljivosti --- svakako je najjednostavniji među beskonačnim skupovima, a izračunljivost na konačnim skupovima je trivijalna: svaki algoritam može se napisati jednostavno kao tablica (\emph{lookup table}).

Odabir skupa $\N$ kao osnovnog isplatit će se kroz jednostavnost mnogih dokaza (jer imamo matematičku indukciju, jasno određen početak i sljedbenika, dobar uređaj,\ldots), ali s druge strane, zato će biti kompliciranije reprezentirati (\emph{kodirati}) razne druge matematičke objekte kao prirodne brojeve. Za usporedbu, skup $\Sigma^*$ je puno zgodniji za kodiranje, jer već imamo intuitivnu reprezentaciju raznih objekata kao nizova znakova ($\Sigma=$ ASCII): recimo, nitko nam ne mora objasniti kodiranje da bismo znali koji element od $\mathbb Q$ predstavlja \verb+'-22/3'+.

Ipak, neintuitivnost kodiranja nadomjestit će lakoća pisanja algoritama: dok je, uz odgovarajuće tehnike (koje ćemo objasniti), lako napisati algoritam za npr.\ zbrajanje racionalnih brojeva kodiranih prirodnim brojevima, odgovarajući algoritam za ASCII-kodirane razlomke gotovo nikada ne stigne dalje od grubog pseudokoda. Treba reći da ćemo ponegdje, gdje su naši objekti već \emph{definirani} kao nizovi znakova (najvažniji primjer su formule logike prvog reda), svakako koristiti njihovu jezičnu reprezentaciju, ali to će biti nakon što objasnimo općenito kodiranje sa $\Sigma^*$ u $\N$ (i obrnuto).

Tehnički detalj koji moramo razriješiti je: smatramo li nulu prirodnim brojem? Treba li brojenje početi od $0$ ili od $1$, dilema je stara koliko i samo računarstvo~\cite{note:EWD831}.
Kao i drugdje u matematici, postoje dobri razlozi i za i protiv. Koristit ćemo oba skupa, no kako će nam češće trebati nula među prirodnim brojevima (pogledajmo definiciju od $\{0,1\}^*$, na primjer), skup s nulom imat će kraću oznaku.
\begin{align}
\N&:=\{\,0,1,2,3,\dotsc\}\\
\N_+&:=\{\,1,2,3,4,\dotsc\}
\end{align}

\subsection{Broj izlaznih i ulaznih podataka}\label{sec:briup}

Pričali smo o izlaznim podacima u množini, no lako je vidjeti da --- s obzirom na to da nas samo zanima postojanje algoritma, ne i njegove performanse --- ništa ne gubimo fiksiranjem broja izlaznih podataka na $1$. Algoritam s $k$ ulaznih i $l$ izlaznih podataka uvijek možemo promatrati kao $l$ algoritama s istih $k$ ulaznih podataka i s po jednim izlaznim podatkom.

Na primjer, u nekim programskim jezicima postoji operacija $\f{divmod}$ iz $\mathbb Z^2$ u $\mathbb Z^2$, koja provodi dijeljenje s ostatkom u $\mathbb Z$, te vraća količnik i ostatak. Nju uvijek možemo, čak i da je nemamo kao osnovnu, emulirati pomoću dvije operacije, $\sslash$ i $\bmod$, koje vraćaju količnik i ostatak istog dijeljenja zasebno. Naravno, razlog zašto neki jezici imaju $\f{divmod}$ kao posebnu funkciju leži u tome da algoritmi za te dvije operacije imaju mnogo zajedničkih koraka, te ako smo odredili npr.\ količnik, obično je vrlo lako iz postupka kojim smo to učinili pročitati i ostatak (sjetite se npr.\ algoritma za dijeljenje višeznamenkastih brojeva). Zato bismo ponovnim provođenjem algoritma ispočetka za ostatak nepotrebno duplicirali korake. No ako nas samo zanima koje su funkcije izračunljive, očito postoji algoritam za $\f{divmod}$ ako i samo ako postoje algoritmi za $\sslash$ i $\bmod$, te nam je dovoljno baviti se pitanjem jesu li $\sslash$ i $\bmod$ izračunljive (u ovom slučaju, dakako, jesu).

Kad promatramo broj \emph{ulaznih} podataka (tzv.\ \emph{mjesnost}) algoritma, situacija je bitno drugačija. Jasno je da algoritam za npr.\ potenciranje prirodnih brojeva prima bazu i eksponent kao dva ulazna podatka, i ne može se (bar ne jednostavno) zapisati pomoću algoritama koji primaju po jedan ulazni podatak. Doduše, korištenjem tehnike \emph{currying}, svaku izračunljivu funkciju možemo računati pomoću algoritama koji primaju po \emph{dva} ulazna podatka, i neki autori doista ograničavaju mjesnost na $2$, ali to stvara dosta tehničkih problema za minimalni dobitak.

\begin{napomena}\label{nap:blokovi}
Važna programerska intuicija koja nam može pomoći u shvaćanju ulaznih podataka: svaki algoritam možemo doživjeti kao programski \emph{blok} naredaba, u kojem uvodimo neke nove varijable, ali nasljeđujemo i sve varijable iz vanjskih blokova. Tako kad napišemo $\f f(\vec x,y,z)$, najčešće mislimo da su nam $\vec x$ varijable "otprije" (izvana) koje možemo koristiti, dok smo uveli još dvije "lokalne" varijable $y$ i $z$ za potrebe konkretnog algoritma.
\end{napomena}

Zato ćemo promatrati algoritme proizvoljnih mjesnosti $k\in\N_+$, i smatrati da mjesnost čini važan dio identiteta algoritma. Važno je napomenuti da su npr.\ "zbroji 2 broja" i "zbroji 5 brojeva" različiti algoritmi (jer su različitih mjesnosti), štoviše ovaj prvi pojavljuje se kao korak (nekoliko puta) u ovom drugom.

Direktna posljedica toga je da u našem modelu ne postoje algoritmi s "varijabilnim brojem" ulaznih podataka (u računarstvu poznati kao \emph{varargs}). Na nekoliko mjesta gdje nam budu potrebni, modelirat ćemo ih pomoću familije algoritama svih mogućih mjesnosti, recimo zbrajanje kao $\f{add}^k$, $k\in\N_+$ (mjesnost algoritma ili funkcije ćemo obično pisati u superskriptu ako je želimo naglasiti --- neće dolaziti do zabune s eksponentima jer algoritme niti funkcije nećemo potencirati, niti s oznakom $f^{-1}$ za inverznu funkciju jer mjesnost ne može biti negativna).

Iako mjesnost smatramo neodvojivim dijelom funkcije odnosno algoritma, u slučaju nespecificirane mjesnosti $k$ nespretno je pisati $x_1,x_2,\dotsc,x_k$ svugdje gdje trebamo napisati argumente odnosno ulazne podatke. Zato ćemo često tih $k$ prirodnih brojeva skraćeno pisati $\vec x$, ili $\vec x^{\,k}$ ako želimo naglasiti koliko ih ima --- no najčešće će se to moći zaključiti iz konteksta: recimo, u $\f{f}^7(\vec x,y,z)$, očito je duljina od $\vec x$ jednaka $5$.

Pažljiv čitatelj će primijetiti da zahtijevamo da mjesnost bude pozitivan prirodan broj, odnosno ne promatramo algoritme s $0$ ulaznih podataka. Ovo nije bitna restrikcija (možete se zabaviti pokušavajući otkriti koje sve tehničke detalje u knjizi treba promijeniti da bismo uključili i takve algoritme u razmatranje), ali komplicira izlaganje, a opet, takvi algoritmi nam nisu zanimljivi iz perspektive izračunljivosti: budući da zahtijevamo determinističnost, nul-mjesni algoritmi mogu računati jedino konstante, a one su svakako izračunljive bez obzira na formalizam.

\subsection{Parcijalnost}

Gdje smo u dosadašnjem tekstu pričali o općenitim izračunljivim funkcijama, pazili smo da  upotrijebimo prijedlog "iz" (funkcija \emph{iz} $A$ u $B$). Općenito u matematici, takva fraza označava \emph{parcijalne} funkcije, koje ne moraju biti definirane u svim točkama od $A$ (precizno, domena im je podskup od $A$). Recimo, tangens je parcijalna funkcija iz $\mathbb R$ u $\mathbb R$, jer $\frac{\pi}{2}\in\mathbb R\setminus \dom{\text{tg}}$. Takve funkcije označavamo oznakom $f\colon A\rightharpoonup B$, za razliku od \emph{totalnih} funkcija koje označavamo $f\colon A\to B$ i zovemo ih funkcije \emph{sa} $A$ u $B$. 

Dopuštajući algoritmima da računaju parcijalne funkcije, zapravo im omogućavamo da je za neke ulazne podatke njihov rad sasvim dobro definiran (ovdje ne mislimo na izuzetke, \emph{exceptions}, kao što je dijeljenje nulom), ali ipak ne postoji završna konfiguracija iz koje bismo mogli pročitati izlazni podatak. Nakon malo razmišljanja dolazimo do zaključka da je to jedino moguće tako da algoritam (za neke ulaze) beskonačno radi, odnosno nikada ne stane.

Nije li to u kontradikciji s naivnom definicijom algoritma, koja kaže da se radi o \emph{konačnom} postupku? Jest, ali to samo pokazuje da naivne definicije nisu dovoljne, i da nam treba formalizacija. Naime, naivna definicija algoritma, baš kao i naivna definicija skupa, vodi na paradoks vrlo sličan Russellovom. \emph{Moramo} u obzir uzeti i parcijalne funkcije, odnosno algoritme koji ne stanu uvijek, ako želimo konzistentnu teoriju. Evo kratke skice argumenta --- precizno ćemo ga provesti kad precizno definiramo pojmove.

Budući da želimo algoritme moći reprezentirati u računalu, moramo ih moći prikazati kao konačne nizove nula i jedinica. Ta reprezentacija mora biti injekcija ako želimo išta raditi s tim algoritmima, a iz teorije skupova znamo da je $\{0,1\}^*$ prebrojiv, dakle \textbf{svih algoritama ima prebrojivo mnogo}. Specijalno, svih jednomjesnih algoritama  ima prebrojivo mnogo (naravno da ih ima beskonačno mnogo). Poredajmo sve jednomjesne algoritme u niz. Pogledajmo sada ovaj jednomjesni algoritam: "Za ulaz $x\in\N$, nađi $x$-ti algoritam u nizu, i primijeni ga na $x$. Izlaz tog algoritma (s ulazom $x$) označi sa $y$. Vrati $y+1$." Jasno je da \emph{taj} algoritam ne može biti na popisu, ako algoritmi računaju totalne funkcije (ako je $r$-ti po redu, tada s ulazom $r$ mora davati i $y$ i $y+1$); ali ako računaju parcijalne funkcije, nema kontradikcije --- jednostavno, $y$ može biti nedefiniran, jer $x$-ti algoritam s ulazom $x$ ne mora stati.

Ipak, jasno je da je puno lakše raditi s totalnim algoritmima, koji računaju totalne funkcije. Parcijalne funkcije moramo dozvoliti u krajnjoj općenitosti, ali mnoge funkcije koje ćemo koristiti u izgradnji teorije bit će ne samo totalne, nego i \emph{dokazivo} totalne unutar teorije koju gradimo: već iz njihovog sintaksnog oblika bit će jasno da algoritmi koji ih računaju uvijek stanu. Takve funkcije zvat ćemo \emph{primitivno rekurzivnima}.

Kad smo već kod toga, recimo nekoliko riječi i o klasičnim izuzecima poput dijeljenja nulom. Primitivno rekurzivne funkcije po definiciji moraju biti totalne, pa si ne možemo priuštiti jednostavno reći nešto poput "$3\sslash0$ nije definirano" (dokazat ćemo da je $\sslash$ primitivno rekurzivna operacija). U mnogim slučajevima to ćemo rješavati jednostavno tako da kažemo "\emph{postoji} primitivno rekurzivna funkcija $\f{f}$ koja se podudara s traženom funkcijom $g$ na domeni $\dom{g}$", ne govoreći ništa o vrijednostima $\f{f}(\vec x)$ za $\vec x\not\in\dom{g}$. Još općenitije, ponekad ćemo umjesto funkcije $g$ navesti samo neko \emph{svojstvo} koje vrijednosti od $\f{f}$ moraju zadovoljavati na nekom skupu. Kazat ćemo tada da smo \emph{parcijalno specificirali} (totalnu) funkciju $\f{f}$: u smislu, $\f{f}$ je definirana svuda, ali nas zanimaju samo vrijednosti na nekom užem skupu.

Treba napomenuti da je važna odlika ove knjige da će svi algoritmi biti precizno specificirani --- ništa neće ostati na pseudokodu. Dakle, uvijek ćemo moći precizno izračunati vrijednosti od $\f{f}$ i izvan skupa na kojem je specificirana (na primjer, algoritam za $\sslash$ reći će nam da je $3\sslash 0=3$). Ponekad će čak te vrijednosti imati neko značenje, u smislu da će takvu funkciju $\f{f}$ biti lakše uklopiti u kasnije definicije bez puno rastava na slučajeve. No to nećemo često koristiti, i svaki put ćemo naglasiti kad se to dogodi.

\subsection{Relacije}

Iako sva računanja možemo shvatiti kao računanja funkcija, izlaganje je jednostavnije ako uvedemo i \emph{relacije}, koje ćemo računati kao specijalni slučaj računanja funkcija. Iz standardne skupovno-teorijske perspektive to se čini čudnim: nisu li relacije općenit pojam, a funkcije samo specijalni slučaj, relacije s funkcijskim svojstvom?

Iz algoritamske perspektive, nisu. Ako izračunljivu funkciju $\f{f}$ reprezentiramo po\-mo\-ću algoritma koji za dani $\vec x$ računa njenu vrijednost $\f{f}(\vec x)$, izračunljivu relaciju $\f{R}$ prirodno je predstaviti algoritmom koji za dani $\vec x$ računa \emph{istinitosnu} vrijednost ($bool$: $\mathit{true}$ ili $\mathit{false}$), već prema tome je li $\vec x\in\f{R}$ ili nije. Većina programskih jezika uopće nema mogućnost definicije relacije kao zasebnog algoritamskog tipa, već ih reprezentiraju funkcijama čiji povratni tip je $bool$.

Na primjer, reći da je dvomjesna relacija uređaja $<$ na prirodnim brojevima iz\-ra\-čun\-lji\-va zapravo znači reći da postoji algoritam koji za sve $(x,y)\in\N^2$ u konačno mnogo koraka vraća $\mathit{true}$ ako je $x<y$, a $\mathit{false}$ inače. Ili, skup prim-brojeva (jednomjesna relacija $\mathbb P$) je izračunljiv jer možemo napisati algoritam $\f{isPrime}\colon\N\to bool$, koji za svaki $x$ u konačno mnogo koraka vraća $\mathit{true}$ ako je $x\in\mathbb P$, a $\mathit{false}$ ako $x\not\in\mathbb P$. Vidimo da ćemo o relacijama pričati bilo pomoću formula s relacijskim simbolima ($\f{R}(\vec x)$, ili $x\mathrel{\f R}y$ za binarne relacije), bilo pomoću skupova ($\vec x\in\f{R}$), kako nam bude zgodnije.

U skladu s uobičajenom praksom modernih programskih jezika, prešutno koristimo standardno ulaganje skupa $bool$ u $\N$, tako da preslikamo $\mathit{false}\mapsto 0$, te $\mathit{true}\mapsto 1$. Drugim riječima, na izračunljivost relacije $R$ gledamo kao na izračunljivost njene \emph{karakteristične funkcije} $\chi_R$, koja je iste mjesnosti kao i $R$. U suprotnom smjeru, kad želimo interpretirati proizvoljni prirodni broj kao $bool$, koristimo (opet standardnu) interpretaciju po kojoj se $0$ interpretira kao $\mathit{false}$, a svi ostali prirodni brojevi kao $\mathit{true}$: drugim riječima, podrazumijevamo kompoziciju s karakterističnom funkcijom $\chi_{\N_+}$ (za koju ćemo dokazati da je izračunljiva).

Dakle, relacijama ćemo pripisivati svojstva izračunljivosti koja imaju njihove karakteristične funkcije: na primjer, reći ćemo da je $\f{R}$ primitivno rekurzivna ako je $\chi_{\f{R}}$ primitivno rekurzivna. Primijetimo da kod relacija ne moramo razmišljati o parcijalnosti: karakteristična funkcija je uvijek totalna. Relacije imaju drugi način iskazivanja parcijalnosti, takozvanu \emph{rekurzivnu prebrojivost}, ali o tome ćemo kasnije.

\section{Notacija}

Iz prethodne točke zaključujemo da ćemo promatrati (algoritme za) dvije vrste funkcija: jezične i brojevne. Brojevne funkcije su nam puno važnije i većinu teorije ćemo napraviti s njima, ali na nekoliko mjesta dobro će nam doći i formalizacija izračunljivosti jezičnih funkcija.

Svaka brojevna funkcija je oblika $f\colon S\to\N$, gdje je $S\subseteq\N^k$ za neki $k\in\N_+$. Skraćeno pišemo $f\colon\N^k\rightharpoonup\N$, ili još kraće $f^k$, ako nam nije bitan skup $S=\dom{f}$. Broj $k$ zovemo \emph{mjesnost} funkcije $f$. Svaka brojevna funkcija ima jedinstvenu mjesnost --- osim prazne funkcije $\varnothing$, čija domena je prazan skup $\emptyset$. Radi jednostavnosti izlaganja, smatrat ćemo da i prazne funkcije imaju fiksnu mjesnost, odnosno umjesto jedne funkcije $\varnothing$ promatrat ćemo familiju $\varnothing^k$, $k\in\N_+$, i smatrat ćemo da su, na primjer, $\varnothing^3$ i $\varnothing^8$ različite funkcije. Formalno, to možemo napraviti tako da nam "funkcija" znači uređen par, kojem je prva komponenta uobičajena reprezentacija funkcije (skup uređenih parova s nekim svojstvom), a druga komponenta mjesnost --- ali nećemo imati potrebu biti toliko formalni, tim više što prazne funkcije nisu zanimljive iz perspektive izračunljivosti: algoritmi koji ih računaju su jednostavno beskonačne petlje.

(Brojevna) relacija je oblika $R\subseteq\N^k$ za neki $k\in\N_+$. Po analogiji s funkcijama, $k$ zovemo \emph{mjesnost} relacije, i pišemo $R^k$ ako ga želimo naglasiti. Kao i za funkcije, iako su sve prazne relacije skupovno jednake (postoji samo jedan prazan skup), promatrat ćemo familiju $\emptyset^k$, $k\in\N_+$, i smatrati sve njene elemente različitim relacijama. Na kraju krajeva, njihove karakteristične funkcije \emph{jesu} različite, jer imaju različite domene: recimo, $\dom{\chi_{\emptyset^3}}=\N^3$. (Radi se o nulfunkciji $\f C_0^3\colon\N^3\to\N$; potrebno je razlikovati nulfunkciju, koja je totalna, od prazne funkcije koja nije definirana nigdje!)

Jezične funkcije ćemo uvijek definirati nad nekom \emph{abecedom} (konačan neprazan skup) $\Sigma$, i to će nam biti funkcije $\varphi\colon\Sigma^*\rightharpoonup\Sigma^*$. Elementi od $\Sigma^*:=\bigcup_{k\in\N}\Sigma^k$ su konačni nizovi \emph{znakova} iz $\Sigma$, koje zovemo \emph{riječi} i pišemo jednostavno konkatenacijom: recimo, $\t{aab}$ umjesto $(\t{a},\t{a},\t{b})$. \emph{Prazna riječ} je niz duljine $0$: označavamo je s $\varepsilon$. Iz oblika jezičnih funkcija vidimo da su one jednomjesne: u svrhu reprezentacije funkcija veće mjesnosti, obično se u abecedu dodaje \emph{separator}, znak koji služi razdvajanju argumenata. Recimo, višemjesne funkcije nad $\{\t{a},\t{b}\}$ možemo reprezentirati kao jednomjesne funkcije nad $\{\t{a},\t{b},\t{,}\}$, tako da primjerice $\varphi^4(\t{a},\t{abb},\varepsilon,\t{ba})$ računamo kao $\dot\varphi^1(\t{a,abb,,ba})$. Kažemo da je $\dot\varphi$ dobivena \emph{kontrakcijom} iz $\varphi$.

Primijetimo da je ovo generalnije od brojevnih višemjesnih funkcija jer možemo imati \emph{varargs} (mjesnost možemo zaključiti jednostavnim brojenjem separatora u ulaznoj ri\-je\-či), ali i dalje nemamo mogućnost prikazivanja nulmjesnih funkcija: $\dot\varphi(\varepsilon)$ je jednostavno $\varphi^1(\varepsilon)$, ne $\varphi^0()$. Sličan trik možemo primijeniti i kod brojevnih funkcija, nakon što definiramo kodiranje skupa $\N^*$.

Analogon pojmu relacije u jezičnom slučaju, dakle podskup od $\Sigma^*$, zovemo jednostavno \emph{jezik}. Iako karakteristična funkcija jezika nije ni brojevna ni jezična funkcija, svejedno možemo pomoću kodiranja skupa $\Sigma^*$ reprezentirati i izračunljivost jezikâ. O tome ćemo također više reći kasnije.

Domenu, sliku i graf funkcije $f$ označavamo redom sa $\dom{f}$, $\im{f}$ i $\graf{f}$. Primijetimo da je, za funkciju mjesnosti $k$, domena relacija mjesnosti $k$, slika relacija mjesnosti $1$, a graf relacija mjesnosti $k+1$.

Brojevne izračunljive funkcije i relacije označavamo posebnim fontom: dok nam $g$ označava proizvoljnu funkciju, $\f{g}$ nam označava funkciju za koju imamo neku vrstu algoritma. U tom smislu, $g(x)$ označava uobičajenu funkcijsku vrijednost (drugu komponentu uređenog para u $g$ čija je prva komponenta $x$), dok $\f{g}(x)$ označava izlazni podatak algoritma za $\f{g}$ pokrenutog s ulaznim podatkom $x$.

Za funkcije i relacije koristit ćemo uobičajene matematičke oznake gdje god možemo: pisat ćemo $x+y+z$ za zbroj tri broja, ili $y\mathrel|x$ za djeljivost, ili $p\in\mathbb P$ za prim-brojeve. No treba imati na umu da su to izračunljive funkcije i relacije (što ćemo dokazati), te da u pozadini stoje algoritmi za $\f{add}^3$, $\f{Divides}^2$, odnosno $\f{isPrime}^1$.

\begin{napomena}\label{nap:parcdef}
Algoritamsku jednakost (izračunljivu dvomjesnu brojevnu relaciju, koja se u modernim programskim jezicima često označava `\t{==}') oz\-na\-ča\-va\-mo uobičajenim simbolom `$=$', koji i inače koristimo za jednakost matematičkih objekata (funkcija, relacija, skupova,\ldots). Kod definicija skupova, i funkcija s prethodno specificiranom domenom (što uključuje totalne funkcije), koristimo simbol `$:=$'. Relacije definiramo formulama koristeći `$:\Longleftrightarrow$'. Često imamo potrebu vrijednosti funkcije specificirati izrazom, uz prešutnu pretpostavku "prirodne domene" (sve ulazne vrijednosti za koje izraz ima smisla). Tada pišemo $f(\vec x):\simeq izraz$. Ovisno o obliku izraza, definirat ćemo precizno značenje fraze "ima smisla".
\end{napomena}

Ponekad ćemo imati potrebu korištenja znaka $\simeq$ između dva izraza, što će značiti da su oni jednaki za one vrijednosti varijabli za koje imaju smisla, te da oba izraza imaju smisla za iste vrijednosti varijabli. Drugačije rečeno, $izraz1\simeq izraz2$ znači da su definicije $f(\vec x):\simeq izraz1$ i $f(\vec x):\simeq izraz2$ ekvivalentne (definiraju istu funkciju), gdje su u $\vec x$ sve varijable koje se pojavljuju bilo u $izraz1$, bilo u $izraz2$. Razlog za nekorištenje znaka = i u takvom slučaju leži u tome što relacija $\simeq$, kao i svojstvo "imati smisla", nisu izračunljive. Još jedan razlog za korištenje neuobičajenog znaka je što mnoga "instinktivna pojednostavljenja" više nisu validna: na primjer, ako je $f^3$ totalna a $g^3$ nije, $f(\vec x)+0\cdot g(\vec x)\not\simeq f(\vec x)$ --- jer izraz zdesna ima smisla za sve $\vec x\in\N^3$, dok izraz slijeva ima smisla samo za $\vec x\in\dom{g}$.

\section{Opća i univerzalna izračunljivost}

Jedan od velikih ciljeva teorije izračunljivosti je pokazati da pojam izračunljive funkcije zapravo ne ovisi o podlozi na kojoj se njen algoritam izvršava. Iako je lako naći prejednostavne sustave (kao što su na primjer konačni automati, koji ne mogu čak niti uspoređivati proizvoljno velike prirodne brojeve), nakon neke točke dovoljne kompleksnosti svi mehanički sustavi postaju \emph{ekvivalentni} po pitanju toga koje funkcije, uz razumno kodiranje njihovih ulaza i izlaza, računaju. To se vidi iz činjenice da je svaki od njih sposoban \emph{simulirati} sve druge, odnosno reprezentirati njihove konfiguracije (ili bar njihove kodove) unutar svojih, i izvršavati korake njihovog računanja kao (možda komplicirane) procedure na svojim konfiguracijama. \emph{Church--\!Turingova teza} ide i dalje: kaže da se ne samo svi algoritmi izvršivi na svim formalnim modelima izračunljivosti, već i svi "intuitivno zamislivi" algoritmi, mogu izvršavati na nekom konkretnom modelu izračunljivosti, primjerice na Turingovom stroju. Tu tezu je očito nemoguće matematički dokazati, ali svaki dokaz ekvivalencije raznih sustava izračunljivosti pruža dodatnu empirijsku potvrdu za nju.

Drugim riječima, izračunljivost je \emph{opći} fenomen: u kojem god modelu da je definiramo, ona će obuhvatiti iste funkcije --- ili bar iste s obzirom na prirodno kodiranje ulaza i izlaza. Na primjer, algoritmi za zbrajanje dekadski zapisanih i binarno zapisanih prirodnih brojeva očito su različiti, ali jednako tako je očito da su oba zapravo samo kodiranja brojevne funkcije $\f{add}^2$, s obzirom na različita kodiranja (dekadsko odnosno binarno) samih prirodnih brojeva.

Također, jedan od tih modela (pa onda i svi ostali, putem simulacije) zapravo posjeduje svojstvo \emph{univerzalnosti}: ne samo da je za svaku izračunljivu funkciju moguće naći algoritam unutar tog modela, već je moguće naći \emph{jedan} algoritam koji, ovisno o ulazima, može računati \emph{sve} izračunljive funkcije, odnosno može simulirati sve ostale algoritme. Štoviše, ta "granica dovoljne kompleksnosti", na kojoj se postiže opća izračunljivost i univerzalnost, je za neke modele začuđujuće nisko. Promotrit ćemo tri tipa takvih sustava.